# ğŸ³ Docker åŒ–åˆ†æå ±å‘Šï¼šMLX DeepSeek-OCR

## ğŸ“‹ åŸ·è¡Œæ‘˜è¦

### âœ… **çµè«–ï¼šå¯ä»¥ Docker åŒ–ï¼Œä½†æœ‰é‡è¦é™åˆ¶**

| é …ç›® | ç‹€æ…‹ | èªªæ˜ |
|------|------|------|
| **Docker åŒ–å¯è¡Œæ€§** | âœ… **å¯è¡Œ** | ä»£ç¢¼çµæ§‹é©åˆå®¹å™¨åŒ– |
| **Linux æ”¯æ´** | âš ï¸ **éƒ¨åˆ†æ”¯æ´** | éœ€è¦ CUDA + MLX CUDA æ”¯æ´ |
| **macOS Docker** | âš ï¸ **å—é™** | ç„¡æ³•ä½¿ç”¨ Metal GPU |
| **é›²ç«¯éƒ¨ç½²** | âš ï¸ **éœ€ç¢ºèª** | ä¾è³´ MLX CUDA æ”¯æ´ |

---

## ğŸ” ä»£ç¢¼åˆ†æçµæœ

### 1. MLX æ¡†æ¶é™åˆ¶ âš ï¸

#### ç•¶å‰é…ç½®
```python
# app.py:5-6
os.environ['MLX_USE_CPU'] = '1'
os.environ['METAL_DEVICE_WRAPPER_TYPE'] = '1'
```

#### é—œéµç™¼ç¾

**MLX æ¡†æ¶æ¼”é€²ï¼š**
- âœ… **2024 å¹´æ›´æ–°**ï¼šMLX æ–°å¢å° NVIDIA CUDA çš„æ”¯æ´
- âš ï¸ **mlx-vlm æ”¯æ´**ï¼šéœ€è¦ç¢ºèª `mlx-vlm==0.3.5` æ˜¯å¦æ”¯æ´ CUDA
- âŒ **macOS Docker**ï¼šå³ä½¿ä½¿ç”¨ Dockerï¼Œä¹Ÿç„¡æ³•ä½¿ç”¨ Metal GPU

**é‹è¡Œæ¨¡å¼ï¼š**
```
macOS (Apple Silicon)
â”œâ”€â”€ Metal GPU æ¨¡å¼ âœ… æœ€ä½³æ€§èƒ½
â””â”€â”€ CPU æ¨¡å¼ âœ… å¯ç”¨ä½†è¼ƒæ…¢

macOS (Intel)
â””â”€â”€ CPU æ¨¡å¼ âœ… å¯ç”¨ä½†å¾ˆæ…¢

Linux (NVIDIA GPU)
â”œâ”€â”€ CUDA æ¨¡å¼ âš ï¸ éœ€ç¢ºèª mlx-vlm æ”¯æ´
â””â”€â”€ CPU æ¨¡å¼ âŒ MLX ä¸æ”¯æ´ Linux CPU

Linux (ç„¡ GPU)
â””â”€â”€ âŒ ä¸æ”¯æ´
```

---

### 2. ä¾è³´é …åˆ†æ

#### æ ¸å¿ƒä¾è³´
```python
# app.py:33-34
import mlx.core as mx
from mlx_vlm import load, generate
```

#### åœ–åƒè™•ç†ä¾è³´
```python
# app.py:22, 28-29
from PIL import Image  # Pillow
import cv2             # opencv-python
import numpy as np     # numpy
```

#### PDF è™•ç†
```python
# app.py:15
import fitz  # PyMuPDF
```

#### å¯é¸ä¾è³´
```python
# app.py:184
from rembg import remove  # èƒŒæ™¯ç§»é™¤ï¼ˆå¯é¸ï¼Œæœ‰ fallbackï¼‰
```

#### å¤šé€²ç¨‹è™•ç†
```python
# app.py:26, 71
import multiprocessing
model_loaded_status = multiprocessing.Value('b', False)
```

**Docker å½±éŸ¿ï¼š**
- âœ… æ‰€æœ‰ä¾è³´éƒ½å¯ä»¥åœ¨ Docker ä¸­å®‰è£
- âš ï¸ `multiprocessing` åœ¨ Docker ä¸­éœ€è¦æ­£ç¢ºé…ç½®
- âœ… `rembg` æ˜¯å¯é¸çš„ï¼Œæœ‰ fallback æ©Ÿåˆ¶

---

### 3. ç³»çµ±è³‡æºéœ€æ±‚

#### è¨˜æ†¶é«”éœ€æ±‚
- æ¨¡å‹åŠ è¼‰ï¼š~2-3GB
- åœ–åƒè™•ç†ç·©è¡ï¼š~500MB-1GB
- **ç¸½è¨ˆï¼šå»ºè­° 4GB+ å¯ç”¨è¨˜æ†¶é«”**

#### CPU éœ€æ±‚
- CPU æ¨¡å¼ï¼š4-8 æ ¸å¿ƒæ¨è–¦
- CUDA æ¨¡å¼ï¼šå–®æ ¸å¿ƒ + GPU å³å¯

#### ç£ç¢Ÿç©ºé–“
- æ¨¡å‹ç·©å­˜ï¼š~800MB-2GB
- è‡¨æ™‚æ–‡ä»¶ï¼š~100MB-500MB

---

## ğŸ³ Docker åŒ–æ–¹æ¡ˆ

### æ–¹æ¡ˆ Aï¼šLinux x86_64 + CUDAï¼ˆæ¨è–¦ç”¨æ–¼é›²ç«¯ï¼‰

#### Dockerfile (Linux + CUDA)

```dockerfile
# ==============================================================================
# MLX DeepSeek-OCR Docker Image (Linux + CUDA)
# ==============================================================================

# ä½¿ç”¨ NVIDIA CUDA åŸºç¤é¡åƒ
FROM nvidia/cuda:12.1.0-runtime-ubuntu22.04

# è¨­ç½®ç’°å¢ƒè®Šæ•¸
ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONUNBUFFERED=1
ENV MLX_USE_CPU=0
ENV HF_HOME=/root/.cache/huggingface

# å®‰è£ç³»çµ±ä¾è³´
RUN apt-get update && apt-get install -y \
    python3.11 \
    python3.11-dev \
    python3-pip \
    build-essential \
    libgl1-mesa-glx \
    libglib2.0-0 \
    libsm6 \
    libxext6 \
    libxrender-dev \
    libgomp1 \
    && rm -rf /var/lib/apt/lists/*

# è¨­ç½® Python 3.11 ç‚ºé è¨­
RUN update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.11 1
RUN update-alternatives --install /usr/bin/pip3 pip3 /usr/bin/pip3 1

# å®‰è£ Python ä¾è³´
COPY requirements.txt /app/requirements.txt
WORKDIR /app

# å®‰è£ MLXï¼ˆéœ€è¦ CUDA æ”¯æ´ç‰ˆæœ¬ï¼‰
RUN pip3 install --no-cache-dir \
    mlx>=0.20.0 \
    mlx-vlm==0.3.5 \
    && pip3 install --no-cache-dir -r requirements.txt

# å¯é¸ï¼šå®‰è£ rembgï¼ˆèƒŒæ™¯ç§»é™¤ï¼‰
RUN pip3 install --no-cache-dir rembg || echo "rembg installation failed, will use fallback"

# è¤‡è£½æ‡‰ç”¨ä»£ç¢¼
COPY . /app

# å‰µå»ºå¿…è¦çš„ç›®éŒ„
RUN mkdir -p /app/uploads /tmp/uploads && \
    chmod 777 /app/uploads /tmp/uploads

# æš´éœ²ç«¯å£
EXPOSE 5000

# å¥åº·æª¢æŸ¥
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
    CMD curl -f http://localhost:5000/api/status || exit 1

# å•Ÿå‹•å‘½ä»¤
CMD ["python3", "app.py"]
```

#### docker-compose.yml

```yaml
version: '3.8'

services:
  mlx-ocr-api:
    build:
      context: .
      dockerfile: Dockerfile
    image: mlx-deepseek-ocr:latest
    container_name: mlx-ocr-api
    ports:
      - "5000:5000"
    environment:
      - MLX_USE_CPU=0
      - HF_HOME=/root/.cache/huggingface
    volumes:
      - ./uploads:/app/uploads
      - model-cache:/root/.cache/huggingface
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/api/status"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

volumes:
  model-cache:
    driver: local
```

#### æ§‹å»ºèˆ‡é‹è¡Œ

```bash
# æ§‹å»ºé¡åƒ
docker build -t mlx-deepseek-ocr:latest .

# é‹è¡Œå®¹å™¨ï¼ˆéœ€è¦ NVIDIA GPUï¼‰
docker run --gpus all -p 5000:5000 \
    -v $(pwd)/uploads:/app/uploads \
    mlx-deepseek-ocr:latest

# æˆ–ä½¿ç”¨ docker-compose
docker-compose up -d
```

---

### æ–¹æ¡ˆ Bï¼šmacOS Dockerï¼ˆåƒ… CPU æ¨¡å¼ï¼‰

#### Dockerfile (macOS)

```dockerfile
# ==============================================================================
# MLX DeepSeek-OCR Docker Image (macOS - CPU æ¨¡å¼)
# ==============================================================================

FROM python:3.11-slim

# è¨­ç½®ç’°å¢ƒè®Šæ•¸
ENV PYTHONUNBUFFERED=1
ENV MLX_USE_CPU=1
ENV METAL_DEVICE_WRAPPER_TYPE=1
ENV HF_HOME=/root/.cache/huggingface

# å®‰è£ç³»çµ±ä¾è³´
RUN apt-get update && apt-get install -y \
    libgl1-mesa-glx \
    libglib2.0-0 \
    libsm6 \
    libxext6 \
    libxrender-dev \
    curl \
    && rm -rf /var/lib/apt/lists/*

# å®‰è£ Python ä¾è³´
COPY requirements.txt /app/requirements.txt
WORKDIR /app

# âš ï¸ æ³¨æ„ï¼šMLX åœ¨ Linux Docker ä¸­å¯èƒ½ç„¡æ³•æ­£å¸¸é‹è¡Œ
# å³ä½¿è¨­ç½® CPU æ¨¡å¼ï¼ŒMLX ä»éœ€è¦ macOS ç’°å¢ƒ
RUN pip3 install --no-cache-dir -r requirements.txt || \
    echo "âš ï¸ MLX installation may fail on Linux"

# è¤‡è£½æ‡‰ç”¨ä»£ç¢¼
COPY . /app

# å‰µå»ºå¿…è¦çš„ç›®éŒ„
RUN mkdir -p /app/uploads /tmp/uploads && \
    chmod 777 /app/uploads /tmp/uploads

# æš´éœ²ç«¯å£
EXPOSE 5000

# å•Ÿå‹•å‘½ä»¤
CMD ["python3", "app.py"]
```

**âš ï¸ é‡è¦é™åˆ¶ï¼š**
- MLX åœ¨ Linux Docker ä¸­**å¯èƒ½ç„¡æ³•é‹è¡Œ**
- å³ä½¿è¨­ç½® `MLX_USE_CPU=1`ï¼ŒMLX ä»éœ€è¦ macOS ç’°å¢ƒ
- **å»ºè­°ï¼šmacOS ä¸Šç›´æ¥é‹è¡Œï¼Œä¸ä½¿ç”¨ Docker**

---

### æ–¹æ¡ˆ Cï¼šæ··åˆæ¶æ§‹ï¼ˆæ¨è–¦ç”Ÿç”¢ç’°å¢ƒï¼‰

#### æ¶æ§‹è¨­è¨ˆ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         é›²ç«¯éƒ¨ç½²æ¶æ§‹                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Web Server  â”‚      â”‚  OCR API    â”‚ â”‚
â”‚  â”‚  (Linux)     â”‚â”€â”€â”€â”€â”€>â”‚  (macOS)    â”‚ â”‚
â”‚  â”‚  Nginx/      â”‚ HTTP â”‚  ç›´æ¥é‹è¡Œ    â”‚ â”‚
â”‚  â”‚  Apache      â”‚      â”‚  (é Docker) â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**èªªæ˜ï¼š**
- Web Serverï¼šLinux Dockerï¼ˆè™•ç†éœæ…‹æ–‡ä»¶å’Œè·¯ç”±ï¼‰
- OCR APIï¼šmacOS ç›´æ¥é‹è¡Œï¼ˆåˆ©ç”¨ Metal GPUï¼‰
- é€šé HTTP API é€šä¿¡

---

## âš ï¸ é—œéµé™åˆ¶èˆ‡æ³¨æ„äº‹é …

### 1. MLX CUDA æ”¯æ´ç‹€æ…‹

**éœ€è¦ç¢ºèªï¼š**
- âœ… MLX 0.20.0+ æ”¯æ´ CUDA
- âš ï¸ `mlx-vlm==0.3.5` æ˜¯å¦æ”¯æ´ CUDAï¼Ÿ
- âš ï¸ æ¨¡å‹ `mlx-community/DeepSeek-OCR-4bit` æ˜¯å¦æ”¯æ´ CUDAï¼Ÿ

**é©—è­‰æ–¹æ³•ï¼š**
```bash
# åœ¨ Linux + CUDA ç’°å¢ƒä¸­æ¸¬è©¦
python3 -c "import mlx.core as mx; print(mx.metal.is_available())"
python3 -c "from mlx_vlm import load; print('mlx-vlm OK')"
```

### 2. å¤šé€²ç¨‹è™•ç†

**Docker é…ç½®ï¼š**
```dockerfile
# ç¢ºä¿ multiprocessing æ­£å¸¸å·¥ä½œ
ENV PYTHONUNBUFFERED=1
```

**ä»£ç¢¼æª¢æŸ¥ï¼š**
```python
# app.py:71
model_loaded_status = multiprocessing.Value('b', False)
```
- âœ… ä½¿ç”¨ `multiprocessing.Value` æ˜¯ Docker å‹å¥½çš„
- âš ï¸ ç¢ºä¿å…±äº«è¨˜æ†¶é«”æ­£ç¢ºé…ç½®

### 3. æ¨¡å‹ä¸‹è¼‰èˆ‡ç·©å­˜

**Docker å·é…ç½®ï¼š**
```yaml
volumes:
  - model-cache:/root/.cache/huggingface
```

**é¦–æ¬¡é‹è¡Œï¼š**
- æ¨¡å‹æœƒè‡ªå‹•ä¸‹è¼‰åˆ° `/root/.cache/huggingface`
- ä½¿ç”¨ volume æŒä¹…åŒ–ï¼Œé¿å…é‡è¤‡ä¸‹è¼‰

### 4. è¨˜æ†¶é«”ç®¡ç†

**Docker è³‡æºé™åˆ¶ï¼š**
```yaml
deploy:
  resources:
    limits:
      memory: 8G
    reservations:
      memory: 4G
```

---

## ğŸ§ª æ¸¬è©¦å»ºè­°

### 1. æœ¬åœ°æ¸¬è©¦ï¼ˆmacOSï¼‰

```bash
# æ¸¬è©¦ Docker æ§‹å»ºï¼ˆä¸é‹è¡Œï¼‰
docker build -t mlx-ocr-test .

# æ¸¬è©¦ä»£ç¢¼èªæ³•
docker run --rm mlx-ocr-test python3 -m py_compile app.py
```

### 2. Linux + CUDA æ¸¬è©¦

```bash
# åœ¨ Linux + NVIDIA GPU ç’°å¢ƒä¸­
docker build -t mlx-ocr-cuda .
docker run --gpus all mlx-ocr-cuda python3 -c "import mlx.core as mx; print('MLX OK')"
```

### 3. åŠŸèƒ½æ¸¬è©¦

```bash
# å•Ÿå‹•å®¹å™¨
docker run --gpus all -p 5000:5000 mlx-ocr-cuda

# æ¸¬è©¦ API
curl http://localhost:5000/api/status
```

---

## ğŸ“Š æ–¹æ¡ˆå°æ¯”

| æ–¹æ¡ˆ | å¹³å° | GPU æ”¯æ´ | æ€§èƒ½ | æ¨è–¦åº¦ |
|------|------|---------|------|--------|
| **æ–¹æ¡ˆ A** | Linux + CUDA | âœ… NVIDIA GPU | â­â­â­â­ | â­â­â­â­ |
| **æ–¹æ¡ˆ B** | macOS Docker | âŒ ç„¡ GPU | â­â­ | â­ |
| **æ–¹æ¡ˆ C** | æ··åˆæ¶æ§‹ | âœ… Metal GPU | â­â­â­â­â­ | â­â­â­â­â­ |

---

## âœ… å»ºè­°èˆ‡çµè«–

### æ¨è–¦æ–¹æ¡ˆ

1. **é–‹ç™¼ç’°å¢ƒ**ï¼šmacOS ç›´æ¥é‹è¡Œï¼ˆä¸ä½¿ç”¨ Dockerï¼‰
2. **æ¸¬è©¦ç’°å¢ƒ**ï¼šLinux + CUDA Dockerï¼ˆéœ€ç¢ºèª MLX CUDA æ”¯æ´ï¼‰
3. **ç”Ÿç”¢ç’°å¢ƒ**ï¼šæ··åˆæ¶æ§‹ï¼ˆWeb Server Docker + OCR API ç›´æ¥é‹è¡Œï¼‰

### å¯¦æ–½æ­¥é©Ÿ

1. **é©—è­‰ MLX CUDA æ”¯æ´**
   ```bash
   # åœ¨ Linux + CUDA ç’°å¢ƒä¸­æ¸¬è©¦
   pip install mlx mlx-vlm
   python3 -c "from mlx_vlm import load; print('OK')"
   ```

2. **æ§‹å»º Docker é¡åƒ**
   ```bash
   docker build -t mlx-ocr:latest .
   ```

3. **æ¸¬è©¦é‹è¡Œ**
   ```bash
   docker run --gpus all -p 5000:5000 mlx-ocr:latest
   ```

4. **ç›£æ§èˆ‡å„ªåŒ–**
   - ç›£æ§è¨˜æ†¶é«”ä½¿ç”¨
   - ç›£æ§ GPU ä½¿ç”¨ç‡
   - å„ªåŒ–æ¨¡å‹åŠ è¼‰ç­–ç•¥

---

## ğŸ“ ç›¸é—œæ–‡ä»¶

- `DEPLOYMENT_GUIDE.md` - éƒ¨ç½²æŒ‡å—
- `ç³»çµ±æ”¯æ´èªªæ˜.md` - ç³»çµ±æ”¯æ´èªªæ˜
- `requirements.txt` - ä¾è³´æ¸…å–®

---

## ğŸ”„ æ›´æ–°æ—¥èªŒ

- **2024-12-XX**ï¼šMLX æ–°å¢ CUDA æ”¯æ´ï¼Œæ›´æ–° Docker åŒ–åˆ†æ
- **æ³¨æ„**ï¼šéœ€è¦å¯¦éš›æ¸¬è©¦ç¢ºèª `mlx-vlm` çš„ CUDA æ”¯æ´ç‹€æ…‹

---

**çµè«–ï¼šä»£ç¢¼å¯ä»¥ Docker åŒ–ï¼Œä½†éœ€è¦ç¢ºèª MLX CUDA æ”¯æ´ã€‚å»ºè­°å…ˆåœ¨ Linux + CUDA ç’°å¢ƒä¸­æ¸¬è©¦é©—è­‰ã€‚**

