# ğŸ³ Docker éƒ¨ç½²æŒ‡å—

## ğŸ“‹ å¿«é€Ÿé–‹å§‹

### å‰ç½®è¦æ±‚

1. **Docker** å·²å®‰è£
2. **NVIDIA Docker**ï¼ˆå¦‚æœä½¿ç”¨ GPUï¼‰
   ```bash
   # å®‰è£ NVIDIA Container Toolkit
   # Ubuntu/Debian
   distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
   curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
   curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list
   sudo apt-get update && sudo apt-get install -y nvidia-container-toolkit
   sudo systemctl restart docker
   ```

### æ§‹å»ºé¡åƒ

```bash
# ä½¿ç”¨é è¨­ Dockerfile (Linux + CUDA)
docker build -t mlx-deepseek-ocr:latest .

# æˆ–ä½¿ç”¨ macOS ç‰ˆæœ¬ï¼ˆæœ‰é™åˆ¶ï¼‰
docker build -f Dockerfile.macos -t mlx-deepseek-ocr:macos .
```

### é‹è¡Œå®¹å™¨

#### æ–¹æ³• 1ï¼šç›´æ¥é‹è¡Œ

```bash
# Linux + CUDA (æ¨è–¦)
docker run --gpus all \
    -p 5000:5000 \
    -v $(pwd)/uploads:/app/uploads \
    -v mlx-model-cache:/root/.cache/huggingface \
    mlx-deepseek-ocr:latest

# macOS (CPU æ¨¡å¼ï¼Œæœ‰é™åˆ¶)
docker run \
    -p 5000:5000 \
    -v $(pwd)/uploads:/app/uploads \
    -v mlx-model-cache:/root/.cache/huggingface \
    mlx-deepseek-ocr:macos
```

#### æ–¹æ³• 2ï¼šä½¿ç”¨ docker-compose

```bash
# å•Ÿå‹•æœå‹™
docker-compose up -d

# æŸ¥çœ‹æ—¥èªŒ
docker-compose logs -f

# åœæ­¢æœå‹™
docker-compose down
```

---

## âš ï¸ é‡è¦é™åˆ¶

### MLX æ¡†æ¶é™åˆ¶

1. **Linux + CUDA**ï¼š
   - âœ… MLX 0.20.0+ æ”¯æ´ CUDA
   - âš ï¸ éœ€è¦ç¢ºèª `mlx-vlm==0.3.5` æ˜¯å¦æ”¯æ´ CUDA
   - âš ï¸ éœ€è¦å¯¦éš›æ¸¬è©¦é©—è­‰

2. **macOS Docker**ï¼š
   - âŒ ç„¡æ³•ä½¿ç”¨ Metal GPU
   - âš ï¸ MLX åœ¨ Linux Docker ä¸­å¯èƒ½ç„¡æ³•é‹è¡Œ
   - âœ… **å»ºè­°ï¼šmacOS ä¸Šç›´æ¥é‹è¡Œï¼Œä¸ä½¿ç”¨ Docker**

3. **Linux CPU æ¨¡å¼**ï¼š
   - âŒ MLX ä¸æ”¯æ´ Linux CPU æ¨¡å¼
   - âŒ å¿…é ˆä½¿ç”¨ CUDAï¼ˆNVIDIA GPUï¼‰

---

## ğŸ§ª æ¸¬è©¦é©—è­‰

### 1. æª¢æŸ¥ MLX æ˜¯å¦å¯ç”¨

```bash
# é€²å…¥å®¹å™¨
docker exec -it mlx-ocr-api bash

# æ¸¬è©¦ MLX
python3 -c "import mlx.core as mx; print('MLX OK')"
python3 -c "from mlx_vlm import load; print('mlx-vlm OK')"
```

### 2. æª¢æŸ¥ API ç‹€æ…‹

```bash
# å¾ä¸»æ©Ÿæ¸¬è©¦
curl http://localhost:5000/api/status

# é æœŸå›æ‡‰
# {"model_loaded": false, "ready": false}
```

### 3. æ¸¬è©¦ OCR åŠŸèƒ½

```bash
# ä¸Šå‚³åœ–ç‰‡æ¸¬è©¦
curl -X POST http://localhost:5000/api/ocr \
    -F "file=@test_image.jpg"
```

---

## ğŸ“Š è³‡æºé…ç½®

### è¨˜æ†¶é«”éœ€æ±‚

```yaml
# docker-compose.yml
deploy:
  resources:
    limits:
      memory: 8G
    reservations:
      memory: 4G
```

### GPU é…ç½®

```yaml
# docker-compose.yml
deploy:
  resources:
    reservations:
      devices:
        - driver: nvidia
          count: 1
          capabilities: [gpu]
```

---

## ğŸ”§ æ•…éšœæ’é™¤

### å•é¡Œ 1ï¼šMLX ç„¡æ³•å°å…¥

**éŒ¯èª¤ï¼š**
```
ModuleNotFoundError: No module named 'mlx'
```

**è§£æ±ºæ–¹æ¡ˆï¼š**
1. ç¢ºèªä½¿ç”¨ CUDA ç‰ˆæœ¬çš„ MLX
2. æª¢æŸ¥ Dockerfile ä¸­çš„ MLX å®‰è£å‘½ä»¤
3. ç¢ºèªåŸºç¤é¡åƒåŒ…å« CUDA æ”¯æ´

### å•é¡Œ 2ï¼šGPU ä¸å¯ç”¨

**éŒ¯èª¤ï¼š**
```
RuntimeError: CUDA not available
```

**è§£æ±ºæ–¹æ¡ˆï¼š**
```bash
# æª¢æŸ¥ NVIDIA Docker
docker run --rm --gpus all nvidia/cuda:12.1.0-base-ubuntu22.04 nvidia-smi

# å¦‚æœå¤±æ•—ï¼Œå®‰è£ NVIDIA Container Toolkit
```

### å•é¡Œ 3ï¼šæ¨¡å‹ä¸‹è¼‰å¤±æ•—

**è§£æ±ºæ–¹æ¡ˆï¼š**
```bash
# æª¢æŸ¥ç¶²è·¯é€£æ¥
docker exec mlx-ocr-api curl -I https://huggingface.co

# æ‰‹å‹•ä¸‹è¼‰æ¨¡å‹åˆ° volume
docker exec mlx-ocr-api python3 -c "from mlx_vlm import load; load('mlx-community/DeepSeek-OCR-4bit')"
```

---

## ğŸ“ ç›¸é—œæ–‡ä»¶

- `DOCKER_ANALYSIS.md` - è©³ç´°çš„ Docker åŒ–åˆ†æ
- `Dockerfile` - Linux + CUDA Dockerfile
- `Dockerfile.macos` - macOS Dockerfileï¼ˆæœ‰é™åˆ¶ï¼‰
- `docker-compose.yml` - Docker Compose é…ç½®

---

## ğŸ¯ æ¨è–¦æ–¹æ¡ˆ

### é–‹ç™¼ç’°å¢ƒ
```bash
# macOS ä¸Šç›´æ¥é‹è¡Œï¼ˆä¸ä½¿ç”¨ Dockerï¼‰
cd /path/to/project
source venv/bin/activate
python3 app.py
```

### æ¸¬è©¦ç’°å¢ƒ
```bash
# Linux + CUDA Docker
docker-compose up -d
```

### ç”Ÿç”¢ç’°å¢ƒ
```bash
# æ··åˆæ¶æ§‹
# - Web Server: Linux Docker
# - OCR API: macOS ç›´æ¥é‹è¡Œï¼ˆåˆ©ç”¨ Metal GPUï¼‰
```

---

**æ³¨æ„ï¼šè«‹å…ˆé©—è­‰ MLX CUDA æ”¯æ´ç‹€æ…‹ï¼Œå†é€²è¡Œç”Ÿç”¢éƒ¨ç½²ï¼**

